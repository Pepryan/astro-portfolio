---
title: "Complete Kubernetes Monitoring Guide"
date: "2024-11-25"
tags: ["kubernetes", "monitoring", "prometheus", "grafana", "observability"]
category: "DevOps"
summary: "Comprehensive guide to monitoring Kubernetes clusters with Prometheus, Grafana, and other observability tools."
author: "Febryan Ramadhan"
difficulty: "Advanced"
keywords: ["kubernetes", "monitoring", "prometheus", "grafana", "observability"]
draft: false
---

# Complete Kubernetes Monitoring Guide

Monitoring Kubernetes clusters is crucial for maintaining application performance, resource utilization, and overall cluster health. This guide covers comprehensive monitoring strategies using industry-standard tools.

## Monitoring Stack Overview

### Core Components

1. **Prometheus** - Metrics collection and storage
2. **Grafana** - Visualization and dashboards
3. **AlertManager** - Alert routing and management
4. **Node Exporter** - Node-level metrics
5. **kube-state-metrics** - Kubernetes object metrics

## Prometheus Setup

### Installation with Helm

```bash
# Add Prometheus community Helm repository
helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
helm repo update

# Install Prometheus stack
helm install prometheus prometheus-community/kube-prometheus-stack \
  --namespace monitoring \
  --create-namespace \
  --set prometheus.prometheusSpec.retention=30d \
  --set prometheus.prometheusSpec.storageSpec.volumeClaimTemplate.spec.resources.requests.storage=50Gi
```

### Custom Configuration

```yaml
# prometheus-values.yaml
prometheus:
  prometheusSpec:
    retention: 30d
    scrapeInterval: 30s
    evaluationInterval: 30s
    resources:
      requests:
        memory: 2Gi
        cpu: 1000m
      limits:
        memory: 4Gi
        cpu: 2000m

grafana:
  adminPassword: "secure-password"
  persistence:
    enabled: true
    size: 10Gi
```

## Key Metrics to Monitor

### Cluster-Level Metrics

- **Node CPU/Memory utilization**
- **Pod resource consumption**
- **Network traffic**
- **Storage usage**
- **API server performance**

### Application Metrics

```yaml
# ServiceMonitor example
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: app-metrics
spec:
  selector:
    matchLabels:
      app: my-application
  endpoints:
  - port: metrics
    interval: 30s
    path: /metrics
```

## Grafana Dashboards

### Essential Dashboards

1. **Kubernetes Cluster Overview**
2. **Node Exporter Full**
3. **Kubernetes Pod Monitoring**
4. **Kubernetes Deployment Monitoring**
5. **Application-specific dashboards**

### Custom Dashboard Example

```json
{
  "dashboard": {
    "title": "Application Performance",
    "panels": [
      {
        "title": "Request Rate",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(http_requests_total[5m])",
            "legendFormat": "{{method}} {{status}}"
          }
        ]
      }
    ]
  }
}
```

## Alerting Rules

### Critical Alerts

```yaml
# alert-rules.yaml
groups:
- name: kubernetes-alerts
  rules:
  - alert: PodCrashLooping
    expr: rate(kube_pod_container_status_restarts_total[15m]) > 0
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "Pod {{ $labels.pod }} is crash looping"

  - alert: NodeNotReady
    expr: kube_node_status_condition{condition="Ready",status="true"} == 0
    for: 5m
    labels:
      severity: critical
    annotations:
      summary: "Node {{ $labels.node }} is not ready"
```

## Log Aggregation

### ELK Stack Integration

```yaml
# filebeat-config.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: filebeat-config
data:
  filebeat.yml: |
    filebeat.inputs:
    - type: container
      paths:
        - /var/log/containers/*.log
      processors:
        - add_kubernetes_metadata:
            host: ${NODE_NAME}
            matchers:
            - logs_path:
                logs_path: "/var/log/containers/"
```

## Distributed Tracing

### Jaeger Setup

```bash
# Install Jaeger operator
kubectl create namespace observability
kubectl apply -f https://github.com/jaegertracing/jaeger-operator/releases/download/v1.41.0/jaeger-operator.yaml -n observability

# Deploy Jaeger instance
kubectl apply -f - <<EOF
apiVersion: jaegertracing.io/v1
kind: Jaeger
metadata:
  name: jaeger
  namespace: observability
spec:
  strategy: production
  storage:
    type: elasticsearch
EOF
```

## Performance Optimization

### Resource Monitoring

```bash
# Check resource usage
kubectl top nodes
kubectl top pods --all-namespaces

# Analyze resource requests vs limits
kubectl describe nodes | grep -A 5 "Allocated resources"
```

### Capacity Planning

- **Historical trend analysis**
- **Resource utilization patterns**
- **Growth projections**
- **Cost optimization opportunities**

## Troubleshooting Common Issues

### High Memory Usage

```bash
# Identify memory-intensive pods
kubectl top pods --sort-by=memory --all-namespaces

# Check for memory leaks
kubectl logs <pod-name> --previous
```

### Network Issues

```bash
# Check network policies
kubectl get networkpolicies --all-namespaces

# Test connectivity
kubectl run test-pod --image=busybox --rm -it -- /bin/sh
```

## Best Practices

1. **Set up proper resource requests and limits**
2. **Implement comprehensive alerting**
3. **Regular backup of monitoring data**
4. **Monitor the monitoring stack itself**
5. **Use labels consistently for better organization**

## Conclusion

Effective Kubernetes monitoring requires a multi-layered approach combining metrics, logs, and traces. Regular review and optimization of your monitoring setup ensures optimal cluster performance and reliability.
